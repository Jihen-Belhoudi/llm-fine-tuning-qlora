{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"82fe8034","cell_type":"markdown","source":"# LLM Fine-Tuning with QLoRA (Senior AI Engineer Notebook)\n\nThis notebook demonstrates **responsible, cost-efficient fine-tuning of a Large Language Model (LLM)** using **PEFT (LoRA / QLoRA)** under realistic compute constraints (Kaggle GPU).","metadata":{}},{"id":"09694ec5","cell_type":"markdown","source":"## 1. Environment Setup\nEnable GPU in Kaggle settings before running.","metadata":{}},{"id":"b37288c0","cell_type":"code","source":"!pip install -q transformers datasets peft bitsandbytes accelerate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-28T19:51:25.723262Z","iopub.execute_input":"2026-01-28T19:51:25.723561Z","iopub.status.idle":"2026-01-28T19:51:32.029732Z","shell.execute_reply.started":"2026-01-28T19:51:25.723536Z","shell.execute_reply":"2026-01-28T19:51:32.029013Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.1/59.1 MB\u001b[0m \u001b[31m34.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":1},{"id":"069ab66c-ef09-4675-b0bd-f06ad640feac","cell_type":"code","source":"import os\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-28T19:51:32.031253Z","iopub.execute_input":"2026-01-28T19:51:32.031523Z","iopub.status.idle":"2026-01-28T19:51:32.035631Z","shell.execute_reply.started":"2026-01-28T19:51:32.031494Z","shell.execute_reply":"2026-01-28T19:51:32.034856Z"}},"outputs":[],"execution_count":2},{"id":"ab4a34fc","cell_type":"code","source":"import torch\nprint('CUDA available:', torch.cuda.is_available())\nprint('GPU:', torch.cuda.get_device_name(0))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-28T19:51:32.036479Z","iopub.execute_input":"2026-01-28T19:51:32.036652Z","iopub.status.idle":"2026-01-28T19:51:35.647060Z","shell.execute_reply.started":"2026-01-28T19:51:32.036636Z","shell.execute_reply":"2026-01-28T19:51:35.646458Z"}},"outputs":[{"name":"stdout","text":"CUDA available: True\nGPU: Tesla T4\n","output_type":"stream"}],"execution_count":3},{"id":"0ced6340-4e97-4d5f-8950-23213454ee5a","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"75fcbf6d","cell_type":"markdown","source":"## 2. Load Tokenizer and Base Model (4-bit Quantized)","metadata":{}},{"id":"430799ad","cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForCausalLM\nimport torch\n\nmodel_name = 'microsoft/phi-3-mini-4k-instruct'\n\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nbase_model = AutoModelForCausalLM.from_pretrained(\n    model_name,\n    device_map='auto',\n    load_in_4bit=True,\n    torch_dtype=torch.float16\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-28T19:51:35.647811Z","iopub.execute_input":"2026-01-28T19:51:35.648101Z","iopub.status.idle":"2026-01-28T19:52:35.811044Z","shell.execute_reply.started":"2026-01-28T19:51:35.648080Z","shell.execute_reply":"2026-01-28T19:52:35.810273Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eb2348df589548d2806cfe4d6b4272bc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d4e715e30a2648778a22455efd477bdd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7d5f45463d5142a28a800419d212d3ab"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/306 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8a9f193f3ead4203bca155fc9844ea14"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/599 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"725c8a821db84772888612f3cd64535c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/967 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3305dff9baf1474f9d1548a56ab0bf39"}},"metadata":{}},{"name":"stderr","text":"`torch_dtype` is deprecated! Use `dtype` instead!\n2026-01-28 19:51:48.094461: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1769629908.277751      55 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1769629908.328688      55 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1769629908.748826      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1769629908.748864      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1769629908.748868      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1769629908.748870      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nThe `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4d6aad6b31f94c91b560cf4a79d87d67"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"498d41495f2b4600a68cfdce105ddd61"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fe354ecd1936494499ecd3bc6e924bed"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/2.67G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3635febbb8ac43f09dedebbd4926f19f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2970c174125e4bd7978f9872bedd02e9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/181 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5ef2f5fbeb304d70b3778a8158730f0d"}},"metadata":{}}],"execution_count":4},{"id":"e9a9def7","cell_type":"markdown","source":"## 3. Baseline Inference","metadata":{}},{"id":"e5b58a8d","cell_type":"code","source":"prompt = 'Explain customer churn in one concise sentence for a business audience.'\ninputs = tokenizer(prompt, return_tensors='pt').to('cuda')\nout = base_model.generate(**inputs, max_new_tokens=40, do_sample=False)\nprint(tokenizer.decode(out[0], skip_special_tokens=True))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-28T19:52:35.813697Z","iopub.execute_input":"2026-01-28T19:52:35.814320Z","iopub.status.idle":"2026-01-28T19:52:38.572307Z","shell.execute_reply.started":"2026-01-28T19:52:35.814293Z","shell.execute_reply":"2026-01-28T19:52:38.571565Z"}},"outputs":[{"name":"stdout","text":"Explain customer churn in one concise sentence for a business audience. Customer churn refers to the rate atquantifying the percentage of customers who stop using a company's services or products within a given time frame.\n\n\nThis metric is crucial for business\n","output_type":"stream"}],"execution_count":5},{"id":"223533d6","cell_type":"markdown","source":"## 4. Create Instruction Dataset","metadata":{}},{"id":"5e5c69f1","cell_type":"code","source":"from datasets import Dataset\nimport json\n\nconcepts = [\n    \"Customer churn\",\n    \"Customer lifetime value\",\n    \"Churn reduction strategy\",\n    \"Customer acquisition cost\",\n    \"Net promoter score\",\n    \"Monthly recurring revenue\",\n    \"Annual recurring revenue\",\n    \"User retention\",\n    \"Upselling strategy\",\n    \"Cross-selling strategy\",\n    \"Customer segmentation\",\n    \"Market penetration\",\n    \"Pricing optimization\",\n    \"Product-market fit\",\n    \"Customer onboarding\",\n    \"Customer engagement\",\n    \"Subscription renewal\",\n    \"Revenue forecasting\",\n    \"Sales funnel\",\n    \"Lead conversion rate\"\n]\n\ntemplates = [\n    {\n        \"definition\": \"is the percentage of customers who stop using a company's product or service over a defined period.\",\n        \"impact\": \"directly affects revenue stability and increases customer acquisition costs.\",\n        \"example\": \"A SaaS company losing 4% of users monthly experiences declining recurring revenue.\"\n    },\n    {\n        \"definition\": \"represents a key business metric used to evaluate customer behavior and long-term value.\",\n        \"impact\": \"influences strategic decisions related to growth, retention, and profitability.\",\n        \"example\": \"An e-commerce company prioritizes high-value customers for loyalty programs.\"\n    },\n    {\n        \"definition\": \"refers to a measurable indicator used to assess business performance over time.\",\n        \"impact\": \"helps leadership identify risks and optimize operational strategies.\",\n        \"example\": \"A telecom operator monitors this metric to reduce customer attrition.\"\n    },\n    {\n        \"definition\": \"is a business concept used to understand customer dynamics and revenue trends.\",\n        \"impact\": \"plays a critical role in forecasting revenue and managing customer relationships.\",\n        \"example\": \"A subscription platform adjusts pricing based on this indicator.\"\n    },\n    {\n        \"definition\": \"describes a strategic approach used by companies to improve customer outcomes.\",\n        \"impact\": \"supports sustainable growth by aligning customer needs with business goals.\",\n        \"example\": \"A fintech startup applies this strategy to reduce account closures.\"\n    }\n]\n\ndata = []\n\nfor concept in concepts:\n    for t in templates:\n        output_json = {\n            \"definition\": f\"{concept} {t['definition']}\",\n            \"business_impact\": f\"This metric {t['impact']}\",\n            \"example\": t[\"example\"]\n        }\n\n        data.append({\n            \"instruction\": (\n                \"You are a senior business analyst. \"\n                \"Answer STRICTLY in JSON with the keys: definition, business_impact, example. \"\n                \"Do not add extra text.\"\n            ),\n            \"input\": concept,\n            \"output\": json.dumps(output_json)\n        })\n\ndataset = Dataset.from_list(data)\n\nlen(dataset), dataset\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-28T19:52:38.573322Z","iopub.execute_input":"2026-01-28T19:52:38.573876Z","iopub.status.idle":"2026-01-28T19:52:47.470993Z","shell.execute_reply.started":"2026-01-28T19:52:38.573849Z","shell.execute_reply":"2026-01-28T19:52:47.470442Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"(100,\n Dataset({\n     features: ['instruction', 'input', 'output'],\n     num_rows: 100\n }))"},"metadata":{}}],"execution_count":6},{"id":"0e3b8ccf","cell_type":"markdown","source":"## 5. Format Dataset for Instruction Tuning","metadata":{}},{"id":"81ff503b","cell_type":"code","source":"def format_example(e):\n    return {\n        'text': f\"<|user|>\\n{e['instruction']}\\n{e['input']}\\n<|assistant|>\\n{e['output']}\"\n    }\n\nformatted = dataset.map(format_example)\nformatted","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-28T19:52:47.471851Z","iopub.execute_input":"2026-01-28T19:52:47.472098Z","iopub.status.idle":"2026-01-28T19:52:47.509179Z","shell.execute_reply.started":"2026-01-28T19:52:47.472075Z","shell.execute_reply":"2026-01-28T19:52:47.508667Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/100 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9e94bea4a8b644bcbe54d27c9fbba37a"}},"metadata":{}},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['instruction', 'input', 'output', 'text'],\n    num_rows: 100\n})"},"metadata":{}}],"execution_count":7},{"id":"ecdc2188","cell_type":"markdown","source":"## 6. Tokenization","metadata":{}},{"id":"0029237d","cell_type":"code","source":"def tokenize(e):\n    return tokenizer(e['text'], truncation=True, max_length=512)\n\ntokenized = formatted.map(tokenize, remove_columns=formatted.column_names)\ntokenized","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-28T19:52:47.509999Z","iopub.execute_input":"2026-01-28T19:52:47.510219Z","iopub.status.idle":"2026-01-28T19:52:47.598718Z","shell.execute_reply.started":"2026-01-28T19:52:47.510198Z","shell.execute_reply":"2026-01-28T19:52:47.598172Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/100 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b4fcb5ed5bfa4b2e944cac9f1003fb29"}},"metadata":{}},{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['input_ids', 'attention_mask'],\n    num_rows: 100\n})"},"metadata":{}}],"execution_count":8},{"id":"22ca9931","cell_type":"markdown","source":"## 7. Configure and Attach LoRA Adapters","metadata":{}},{"id":"4989a148","cell_type":"code","source":"from peft import LoraConfig, get_peft_model\n\nlora_config = LoraConfig(\n    r=8,\n    lora_alpha=16,\n    target_modules=['qkv_proj', 'o_proj'],\n    lora_dropout=0.05,\n    bias='none',\n    task_type='CAUSAL_LM'\n)\n\nmodel = get_peft_model(base_model, lora_config)\nmodel.print_trainable_parameters()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-28T19:52:47.599497Z","iopub.execute_input":"2026-01-28T19:52:47.599748Z","iopub.status.idle":"2026-01-28T19:52:48.133283Z","shell.execute_reply.started":"2026-01-28T19:52:47.599725Z","shell.execute_reply":"2026-01-28T19:52:48.132344Z"}},"outputs":[{"name":"stdout","text":"trainable params: 4,718,592 || all params: 3,825,798,144 || trainable%: 0.1233\n","output_type":"stream"}],"execution_count":9},{"id":"2405b9e0","cell_type":"markdown","source":"## 8. Training Configuration","metadata":{}},{"id":"671059ff","cell_type":"code","source":"from transformers import TrainingArguments\n\ntraining_args = TrainingArguments(\n    output_dir='./lora-phi3',\n    per_device_train_batch_size=1,\n    gradient_accumulation_steps=8,\n    learning_rate=2e-4,\n    num_train_epochs=3,\n    fp16=True,\n    logging_steps=10,\n    report_to='none'\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-28T19:52:48.134491Z","iopub.execute_input":"2026-01-28T19:52:48.134774Z","iopub.status.idle":"2026-01-28T19:52:48.207351Z","shell.execute_reply.started":"2026-01-28T19:52:48.134749Z","shell.execute_reply":"2026-01-28T19:52:48.206807Z"}},"outputs":[],"execution_count":10},{"id":"d6b34e62","cell_type":"markdown","source":"## 9. Train LoRA Adapters","metadata":{}},{"id":"27e5e071","cell_type":"code","source":"from transformers import Trainer, DataCollatorForLanguageModeling\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized,\n    data_collator=DataCollatorForLanguageModeling(tokenizer, mlm=False)\n)\n\ntrainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-28T19:52:48.208148Z","iopub.execute_input":"2026-01-28T19:52:48.208418Z","iopub.status.idle":"2026-01-28T19:55:01.303711Z","shell.execute_reply.started":"2026-01-28T19:52:48.208372Z","shell.execute_reply":"2026-01-28T19:55:01.303081Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='39' max='39' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [39/39 02:07, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>10</td>\n      <td>1.978400</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>1.073100</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>0.678800</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=39, training_loss=1.0764971757546449, metrics={'train_runtime': 130.9816, 'train_samples_per_second': 2.29, 'train_steps_per_second': 0.298, 'total_flos': 747397701918720.0, 'train_loss': 1.0764971757546449, 'epoch': 3.0})"},"metadata":{}}],"execution_count":11},{"id":"c31324b9","cell_type":"markdown","source":"## 10. Save Fine-Tuned Adapters","metadata":{}},{"id":"46121fb6","cell_type":"code","source":"trainer.save_model('./lora-phi3')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-28T19:55:01.305120Z","iopub.execute_input":"2026-01-28T19:55:01.305370Z","iopub.status.idle":"2026-01-28T19:55:01.727304Z","shell.execute_reply.started":"2026-01-28T19:55:01.305346Z","shell.execute_reply":"2026-01-28T19:55:01.726460Z"}},"outputs":[],"execution_count":12},{"id":"08baf5a6","cell_type":"markdown","source":"## 11. Load Fine-Tuned Model and Compare Outputs","metadata":{}},{"id":"81b9c7c6","cell_type":"code","source":"from peft import PeftModel\n\nft_model = PeftModel.from_pretrained(\n    AutoModelForCausalLM.from_pretrained(\n        model_name,\n        device_map='auto',\n        load_in_4bit=True,\n        torch_dtype=torch.float16\n    ),\n    './lora-phi3'\n)\n\nbase_out = base_model.generate(**inputs, max_new_tokens=40, do_sample=False)\nft_out = ft_model.generate(**inputs, max_new_tokens=40, do_sample=False)\n\nprint('BASE MODEL:\\n', tokenizer.decode(base_out[0], skip_special_tokens=True))\nprint('\\nFINE-TUNED MODEL:\\n', tokenizer.decode(ft_out[0], skip_special_tokens=True))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-28T19:55:01.728248Z","iopub.execute_input":"2026-01-28T19:55:01.728517Z","iopub.status.idle":"2026-01-28T19:55:18.028416Z","shell.execute_reply.started":"2026-01-28T19:55:01.728492Z","shell.execute_reply":"2026-01-28T19:55:18.027761Z"}},"outputs":[{"name":"stderr","text":"The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0f7a3e174a424e2aa570f1b41cb840cf"}},"metadata":{}},{"name":"stdout","text":"BASE MODEL:\n Explain customer churn in one concise sentence for a business audience. Customer churn refers to the rate atemeny businesses monitor to gauge customer retention and loyalty.\n\nCustomer churn is a critical metric for businesses to understand customer retention and\n\nFINE-TUNED MODEL:\n Explain customer churn in one concise sentence for a business audience. Customer churn refers to the rate atemeny businesses monitor to gauge customer retention and loyalty.\n\nCustomer churn is a critical metric for businesses to understand customer retention and\n","output_type":"stream"}],"execution_count":13},{"id":"dab8f160","cell_type":"markdown","source":"## 12. Conclusion\n\n- QLoRA enables fine-tuning on low-memory GPUs.\n- Only ~0.1% of parameters are trained.\n- Fine-tuning is most useful for **behavior and format alignment**, not generic knowledge.","metadata":{}}]}